#!/usr/bin/env python3
"""
PostgreSQL í…Œì´ë¸” ë¶„ì„ ì „ìš© ìŠ¤í¬ë¦½íŠ¸
ë”ìš± ì •í™•í•˜ê³  ìƒì„¸í•œ í…Œì´ë¸” ë¶„ì„ ê¸°ëŠ¥ ì œê³µ
"""

from db_connection import PostgreSQLConnection
import json
from datetime import datetime

class PostgreSQLTableAnalyzer:
    """PostgreSQL í…Œì´ë¸” ë¶„ì„ ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.db = PostgreSQLConnection()
        
    def connect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        return self.db.connect()
    
    def disconnect(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ"""
        self.db.disconnect()
    
    def get_all_tables(self):
        """ëª¨ë“  í…Œì´ë¸” ëª©ë¡ê³¼ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ"""
        query = """
        SELECT 
            t.tablename,
            t.schemaname,
            t.tableowner,
            t.hasindexes,
            t.hasrules,
            t.hastriggers,
            pg_size_pretty(pg_total_relation_size(quote_ident(t.schemaname)||'.'||quote_ident(t.tablename))) as total_size,
            pg_size_pretty(pg_relation_size(quote_ident(t.schemaname)||'.'||quote_ident(t.tablename))) as table_size,
            c.reltuples::bigint as estimated_rows
        FROM pg_tables t
        LEFT JOIN pg_class c ON c.relname = t.tablename
        WHERE t.schemaname = 'public'
        ORDER BY pg_total_relation_size(quote_ident(t.schemaname)||'.'||quote_ident(t.tablename)) DESC
        """
        return self.db.execute_query(query)
    
    def get_table_columns_detailed(self, table_name):
        """í…Œì´ë¸” ì»¬ëŸ¼ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        query = """
        SELECT 
            c.column_name,
            c.data_type,
            c.character_maximum_length,
            c.numeric_precision,
            c.numeric_scale,
            c.is_nullable,
            c.column_default,
            c.ordinal_position,
            CASE 
                WHEN pk.column_name IS NOT NULL THEN 'PRIMARY KEY'
                WHEN fk.column_name IS NOT NULL THEN 'FOREIGN KEY'
                WHEN uk.column_name IS NOT NULL THEN 'UNIQUE'
                ELSE NULL
            END as constraint_type,
            pgd.description as column_comment
        FROM information_schema.columns c
        LEFT JOIN (
            SELECT ku.column_name
            FROM information_schema.table_constraints tc
            JOIN information_schema.key_column_usage ku
                ON tc.constraint_name = ku.constraint_name
            WHERE tc.table_name = %s AND tc.constraint_type = 'PRIMARY KEY'
        ) pk ON c.column_name = pk.column_name
        LEFT JOIN (
            SELECT ku.column_name
            FROM information_schema.table_constraints tc
            JOIN information_schema.key_column_usage ku
                ON tc.constraint_name = ku.constraint_name
            WHERE tc.table_name = %s AND tc.constraint_type = 'FOREIGN KEY'
        ) fk ON c.column_name = fk.column_name
        LEFT JOIN (
            SELECT ku.column_name
            FROM information_schema.table_constraints tc
            JOIN information_schema.key_column_usage ku
                ON tc.constraint_name = ku.constraint_name
            WHERE tc.table_name = %s AND tc.constraint_type = 'UNIQUE'
        ) uk ON c.column_name = uk.column_name
        LEFT JOIN pg_catalog.pg_description pgd
            ON pgd.objoid = (SELECT oid FROM pg_class WHERE relname = %s)
            AND pgd.objsubid = c.ordinal_position
        WHERE c.table_name = %s
        ORDER BY c.ordinal_position
        """
        return self.db.execute_query(query, (table_name, table_name, table_name, table_name, table_name))
    
    def get_table_indexes(self, table_name):
        """í…Œì´ë¸” ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ"""
        query = """
        SELECT 
            indexname,
            indexdef,
            pg_size_pretty(pg_relation_size(indexname::regclass)) as index_size,
            idx_scan as scan_count,
            idx_tup_read as tuples_read,
            idx_tup_fetch as tuples_fetched
        FROM pg_indexes 
        LEFT JOIN pg_stat_user_indexes ON pg_stat_user_indexes.indexrelname = pg_indexes.indexname
        WHERE tablename = %s
        ORDER BY pg_relation_size(indexname::regclass) DESC
        """
        return self.db.execute_query(query, (table_name,))
    
    def get_table_constraints(self, table_name):
        """í…Œì´ë¸” ì œì•½ì¡°ê±´ ì •ë³´ ì¡°íšŒ"""
        query = """
        SELECT 
            tc.constraint_name,
            tc.constraint_type,
            kcu.column_name,
            tc.is_deferrable,
            tc.initially_deferred,
            rc.match_option,
            rc.update_rule,
            rc.delete_rule,
            ccu.table_name AS foreign_table_name,
            ccu.column_name AS foreign_column_name
        FROM information_schema.table_constraints tc
        LEFT JOIN information_schema.key_column_usage kcu
            ON tc.constraint_name = kcu.constraint_name
        LEFT JOIN information_schema.referential_constraints rc
            ON tc.constraint_name = rc.constraint_name
        LEFT JOIN information_schema.constraint_column_usage ccu
            ON rc.unique_constraint_name = ccu.constraint_name
        WHERE tc.table_name = %s
        ORDER BY tc.constraint_type, tc.constraint_name
        """
        return self.db.execute_query(query, (table_name,))
    
    def get_spatial_info(self, table_name):
        """ê³µê°„ ë°ì´í„° ì •ë³´ ì¡°íšŒ"""
        query = """
        SELECT 
            f_geometry_column as geom_column,
            coord_dimension as dimensions,
            srid,
            type as geometry_type
        FROM geometry_columns 
        WHERE f_table_name = %s
        """
        return self.db.execute_query(query, (table_name,))
    
    def get_spatial_extent(self, table_name, geom_column):
        """ê³µê°„ ë°ì´í„° ë²”ìœ„ ì¡°íšŒ"""
        query = f"""
        SELECT 
            ST_XMin(ST_Extent({geom_column})) as min_x,
            ST_YMin(ST_Extent({geom_column})) as min_y,
            ST_XMax(ST_Extent({geom_column})) as max_x,
            ST_YMax(ST_Extent({geom_column})) as max_y,
            COUNT(*) as geom_count,
            COUNT(*) FILTER (WHERE {geom_column} IS NOT NULL) as valid_geom_count
        FROM "{table_name}"
        """
        return self.db.execute_query(query)
    
    def get_table_statistics(self, table_name):
        """í…Œì´ë¸” í†µê³„ ì •ë³´ ì¡°íšŒ"""
        query = f"""
        SELECT 
            schemaname,
            tablename,
            attname as column_name,
            n_distinct,
            correlation,
            most_common_vals,
            most_common_freqs,
            histogram_bounds
        FROM pg_stats 
        WHERE tablename = %s
        ORDER BY attname
        """
        return self.db.execute_query(query, (table_name,))
    
    def get_table_activity(self, table_name):
        """í…Œì´ë¸” í™œë™ í†µê³„ ì¡°íšŒ"""
        query = """
        SELECT 
            seq_scan,
            seq_tup_read,
            idx_scan,
            idx_tup_fetch,
            n_tup_ins,
            n_tup_upd,
            n_tup_del,
            n_tup_hot_upd,
            n_live_tup,
            n_dead_tup,
            last_vacuum,
            last_autovacuum,
            last_analyze,
            last_autoanalyze
        FROM pg_stat_user_tables 
        WHERE relname = %s
        """
        return self.db.execute_query(query, (table_name,))
    
    def analyze_table_comprehensive(self, table_name):
        """í…Œì´ë¸” ì¢…í•© ë¶„ì„"""
        print(f"\n{'='*60}")
        print(f"ğŸ” í…Œì´ë¸” '{table_name}' ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
        print(f"{'='*60}")
        print(f"ğŸ“… ë¶„ì„ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        try:
            # 1. ê¸°ë³¸ ì •ë³´
            print(f"\nğŸ“Š 1. ê¸°ë³¸ ì •ë³´")
            print("â”€" * 30)
            
            tables_info = self.get_all_tables()
            table_info = next((t for t in tables_info if t['tablename'] == table_name), None)
            
            if table_info:
                print(f"   í…Œì´ë¸”ëª…: {table_info['tablename']}")
                print(f"   ìŠ¤í‚¤ë§ˆ: {table_info['schemaname']}")
                print(f"   ì†Œìœ ì: {table_info['tableowner']}")
                print(f"   ì „ì²´ í¬ê¸°: {table_info['total_size']}")
                print(f"   í…Œì´ë¸” í¬ê¸°: {table_info['table_size']}")
                print(f"   ì˜ˆìƒ ë ˆì½”ë“œ ìˆ˜: {table_info['estimated_rows']:,}")
                print(f"   ì¸ë±ìŠ¤ ë³´ìœ : {'ì˜ˆ' if table_info['hasindexes'] else 'ì•„ë‹ˆì˜¤'}")
                print(f"   ê·œì¹™ ë³´ìœ : {'ì˜ˆ' if table_info['hasrules'] else 'ì•„ë‹ˆì˜¤'}")
                print(f"   íŠ¸ë¦¬ê±° ë³´ìœ : {'ì˜ˆ' if table_info['hastriggers'] else 'ì•„ë‹ˆì˜¤'}")
            
            # 2. ì»¬ëŸ¼ ì •ë³´
            print(f"\nğŸ“‹ 2. ì»¬ëŸ¼ ì •ë³´")
            print("â”€" * 30)
            
            columns = self.get_table_columns_detailed(table_name)
            print(f"   ì´ ì»¬ëŸ¼ ìˆ˜: {len(columns)}")
            print(f"\n   {'ìˆœë²ˆ':<4} {'ì»¬ëŸ¼ëª…':<25} {'ë°ì´í„°íƒ€ì…':<20} {'NULLí—ˆìš©':<8} {'ì œì•½ì¡°ê±´':<15}")
            print("   " + "â”€" * 80)
            
            for col in columns:
                data_type = col['data_type']
                if col['character_maximum_length']:
                    data_type += f"({col['character_maximum_length']})"
                elif col['numeric_precision']:
                    if col['numeric_scale']:
                        data_type += f"({col['numeric_precision']},{col['numeric_scale']})"
                    else:
                        data_type += f"({col['numeric_precision']})"
                
                nullable = "ì˜ˆ" if col['is_nullable'] == 'YES' else "ì•„ë‹ˆì˜¤"
                constraint = col['constraint_type'] if col['constraint_type'] else ""
                
                print(f"   {col['ordinal_position']:<4} {col['column_name']:<25} {data_type:<20} {nullable:<8} {constraint:<15}")
            
            # 3. ì¸ë±ìŠ¤ ì •ë³´
            print(f"\nğŸ” 3. ì¸ë±ìŠ¤ ì •ë³´")
            print("â”€" * 30)
            
            indexes = self.get_table_indexes(table_name)
            if indexes:
                for idx in indexes:
                    print(f"   ğŸ“Œ {idx['indexname']}")
                    print(f"      í¬ê¸°: {idx['index_size']}")
                    print(f"      ìŠ¤ìº” íšŸìˆ˜: {idx['scan_count'] if idx['scan_count'] else 0:,}")
                    print(f"      ì½ì€ íŠœí”Œ: {idx['tuples_read'] if idx['tuples_read'] else 0:,}")
                    print(f"      ê°€ì ¸ì˜¨ íŠœí”Œ: {idx['tuples_fetched'] if idx['tuples_fetched'] else 0:,}")
                    print(f"      ì •ì˜: {idx['indexdef']}")
                    print()
            else:
                print("   ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 4. ì œì•½ì¡°ê±´ ì •ë³´
            print(f"\nğŸ”’ 4. ì œì•½ì¡°ê±´ ì •ë³´")
            print("â”€" * 30)
            
            constraints = self.get_table_constraints(table_name)
            if constraints:
                constraint_types = {
                    'PRIMARY KEY': 'ğŸ”‘ ê¸°ë³¸í‚¤',
                    'FOREIGN KEY': 'ğŸ”— ì™¸ë˜í‚¤',
                    'UNIQUE': 'ğŸš« ìœ ë‹ˆí¬',
                    'CHECK': 'âœ… ì²´í¬',
                    'NOT NULL': 'â— NOT NULL'
                }
                
                for constraint in constraints:
                    ctype = constraint_types.get(constraint['constraint_type'], constraint['constraint_type'])
                    print(f"   {ctype}: {constraint['constraint_name']}")
                    print(f"      ì»¬ëŸ¼: {constraint['column_name']}")
                    
                    if constraint['foreign_table_name']:
                        print(f"      ì°¸ì¡° í…Œì´ë¸”: {constraint['foreign_table_name']}.{constraint['foreign_column_name']}")
                        print(f"      ì—…ë°ì´íŠ¸ ê·œì¹™: {constraint['update_rule']}")
                        print(f"      ì‚­ì œ ê·œì¹™: {constraint['delete_rule']}")
                    print()
            else:
                print("   ì œì•½ì¡°ê±´ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # 5. ê³µê°„ ë°ì´í„° ì •ë³´
            print(f"\nğŸŒ 5. ê³µê°„ ë°ì´í„° ì •ë³´")
            print("â”€" * 30)
            
            spatial_info = self.get_spatial_info(table_name)
            if spatial_info:
                for geom in spatial_info:
                    print(f"   ì§€ì˜¤ë©”íŠ¸ë¦¬ ì»¬ëŸ¼: {geom['geom_column']}")
                    print(f"   ì§€ì˜¤ë©”íŠ¸ë¦¬ íƒ€ì…: {geom['geometry_type']}")
                    print(f"   ì°¨ì›: {geom['dimensions']}D")
                    print(f"   SRID: {geom['srid']}")
                    
                    # ê³µê°„ ë²”ìœ„ ì¡°íšŒ
                    extent = self.get_spatial_extent(table_name, geom['geom_column'])
                    if extent and extent[0]['min_x']:
                        ext = extent[0]
                        print(f"   ê³µê°„ ë²”ìœ„:")
                        print(f"      X: {ext['min_x']:.6f} ~ {ext['max_x']:.6f}")
                        print(f"      Y: {ext['min_y']:.6f} ~ {ext['max_y']:.6f}")
                        print(f"      ì´ í”¼ì²˜ ìˆ˜: {ext['geom_count']:,}")
                        print(f"      ìœ íš¨ ì§€ì˜¤ë©”íŠ¸ë¦¬ ìˆ˜: {ext['valid_geom_count']:,}")
                    print()
            else:
                print("   ê³µê°„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            # 6. í…Œì´ë¸” í™œë™ í†µê³„
            print(f"\nğŸ“ˆ 6. í…Œì´ë¸” í™œë™ í†µê³„")
            print("â”€" * 30)
            
            activity = self.get_table_activity(table_name)
            if activity:
                act = activity[0]
                print(f"   ìˆœì°¨ ìŠ¤ìº”: {act['seq_scan'] if act['seq_scan'] else 0:,}")
                print(f"   ìˆœì°¨ ìŠ¤ìº”ìœ¼ë¡œ ì½ì€ íŠœí”Œ: {act['seq_tup_read'] if act['seq_tup_read'] else 0:,}")
                print(f"   ì¸ë±ìŠ¤ ìŠ¤ìº”: {act['idx_scan'] if act['idx_scan'] else 0:,}")
                print(f"   ì¸ë±ìŠ¤ë¡œ ê°€ì ¸ì˜¨ íŠœí”Œ: {act['idx_tup_fetch'] if act['idx_tup_fetch'] else 0:,}")
                print(f"   ì‚½ì…ëœ íŠœí”Œ: {act['n_tup_ins'] if act['n_tup_ins'] else 0:,}")
                print(f"   ì—…ë°ì´íŠ¸ëœ íŠœí”Œ: {act['n_tup_upd'] if act['n_tup_upd'] else 0:,}")
                print(f"   ì‚­ì œëœ íŠœí”Œ: {act['n_tup_del'] if act['n_tup_del'] else 0:,}")
                print(f"   í™œì„± íŠœí”Œ: {act['n_live_tup'] if act['n_live_tup'] else 0:,}")
                print(f"   ì£½ì€ íŠœí”Œ: {act['n_dead_tup'] if act['n_dead_tup'] else 0:,}")
                print(f"   ë§ˆì§€ë§‰ VACUUM: {act['last_vacuum'] if act['last_vacuum'] else 'ì—†ìŒ'}")
                print(f"   ë§ˆì§€ë§‰ ë¶„ì„: {act['last_analyze'] if act['last_analyze'] else 'ì—†ìŒ'}")
            
            # 7. ìƒ˜í”Œ ë°ì´í„°
            print(f"\nğŸ“„ 7. ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ 5ê°œ)")
            print("â”€" * 30)
            
            sample_query = f'SELECT * FROM "{table_name}" LIMIT 5'
            sample_data = self.db.execute_query(sample_query)
            
            if sample_data:
                for i, row in enumerate(sample_data, 1):
                    print(f"   ë ˆì½”ë“œ {i}:")
                    for key, value in row.items():
                        if isinstance(value, str) and len(str(value)) > 50:
                            display_value = str(value)[:47] + "..."
                        else:
                            display_value = value
                        print(f"      {key}: {display_value}")
                    print()
            
            print(f"\n{'='*60}")
            print("âœ… ë¶„ì„ ì™„ë£Œ")
            print(f"{'='*60}")
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    analyzer = PostgreSQLTableAnalyzer()
    
    if not analyzer.connect():
        print("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨!")
        return
    
    try:
        print("ğŸ” PostgreSQL í…Œì´ë¸” ìƒì„¸ ë¶„ì„ê¸°")
        print("=" * 50)
        
        # í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        tables = analyzer.get_all_tables()
        
        print("\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸”:")
        for i, table in enumerate(tables, 1):
            print(f"   {i:2d}. {table['tablename']} ({table['total_size']})")
        
        while True:
            try:
                choice = input(f"\në¶„ì„í•  í…Œì´ë¸” ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{len(tables)}, 0=ì¢…ë£Œ): ").strip()
                
                if choice == '0':
                    break
                
                table_index = int(choice) - 1
                if 0 <= table_index < len(tables):
                    selected_table = tables[table_index]['tablename']
                    analyzer.analyze_table_comprehensive(selected_table)
                    
                    save_choice = input("\në¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower().strip()
                    if save_choice in ['y', 'yes', 'ì˜ˆ']:
                        # JSON í˜•íƒœë¡œ ì €ì¥ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥
                        print(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {selected_table}_analysis.txt")
                else:
                    print("âŒ ì˜ëª»ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
                    
            except ValueError:
                print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            except KeyboardInterrupt:
                print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
    
    finally:
        analyzer.disconnect()

if __name__ == "__main__":
    main()
