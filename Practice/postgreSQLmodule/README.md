# PostgreSQL Module

PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì™€ì˜ ì—°ë™, ë°ì´í„° ì²˜ë¦¬, ë¶„ì„, ë‚´ë³´ë‚´ê¸°ë¥¼ ìœ„í•œ í†µí•© ëª¨ë“ˆì…ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

### 1. ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ (`database.py`)
- PostgreSQL ì—°ê²° ë° ê´€ë¦¬
- ì¿¼ë¦¬ ì‹¤í–‰ ë° íŠ¸ëœì­ì…˜ ì²˜ë¦¬
- DataFrameê³¼ì˜ ì–‘ë°©í–¥ ë³€í™˜
- í…Œì´ë¸” ì •ë³´ ì¡°íšŒ ë° ë°±ì—…

### 2. ë°ì´í„° ì²˜ë¦¬ (`data_processor.py`)
- ë°ì´í„° ì •ë¦¬ ë° ì „ì²˜ë¦¬
- ì»¬ëŸ¼ëª… í‘œì¤€í™”
- ë°ì´í„° íƒ€ì… ë³€í™˜
- í•„í„°ë§, ì§‘ê³„, í”¼ë²— ë“±

### 3. ë°ì´í„° ë¶„ì„ (`analyzer.py`)
- ê¸°ìˆ í†µê³„ ë¶„ì„
- ìƒê´€ê´€ê³„ ë¶„ì„
- ë¶„í¬ ë° ì´ìƒì¹˜ ë¶„ì„
- ì‹œê³„ì—´ ë¶„ì„
- ê°€ì„¤ ê²€ì •

### 4. ë°ì´í„° ë‚´ë³´ë‚´ê¸° (`exporter.py`)
- ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì› (CSV, Excel, JSON, Parquet, HTML)
- ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
- ë°ì´í„° ì‚¬ì „ ìƒì„±

### 5. í†µí•© ì›Œí¬í”Œë¡œìš° (`integration.py`)
- ëª¨ë“  ëª¨ë“ˆì„ í†µí•©í•œ ì™„ì „ ìë™í™” ë¶„ì„
- í…Œì´ë¸” ë¹„êµ ë¶„ì„
- ì‚¬ìš©ì ì •ì˜ ì¿¼ë¦¬ ë¶„ì„

## ğŸ“¦ ì„¤ì¹˜

```bash
# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

## ğŸ”§ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from postgreSQLmodule import PostgreSQLManager, DataProcessor, DataAnalyzer, DataExporter

# 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
db = PostgreSQLManager(
    host="your_host",
    database="your_db", 
    user="your_user",
    password="your_password"
)

if db.connect():
    # 2. ë°ì´í„° ë¡œë“œ
    df = db.to_dataframe("SELECT * FROM your_table")
    
    # 3. ë°ì´í„° ì²˜ë¦¬
    processor = DataProcessor()
    cleaned_df = processor.clean_data(df)
    
    # 4. ë°ì´í„° ë¶„ì„
    analyzer = DataAnalyzer()
    stats = analyzer.descriptive_statistics(cleaned_df)
    
    # 5. ê²°ê³¼ ë‚´ë³´ë‚´ê¸°
    exporter = DataExporter()
    exporter.to_csv(cleaned_df, "processed_data.csv")
    
    db.disconnect()
```

### í†µí•© í´ë˜ìŠ¤ ì‚¬ìš© (ê¶Œì¥)

```python
from postgreSQLmodule.integration import PostgreSQLIntegrator

# Context manager ì‚¬ìš©
with PostgreSQLIntegrator() as integrator:
    # í…Œì´ë¸” ì™„ì „ ë¶„ì„
    result = integrator.analyze_table("your_table")
    
    # ì—¬ëŸ¬ í…Œì´ë¸” ë¹„êµ
    comparison = integrator.compare_tables(["table1", "table2"])
    
    # ì‚¬ìš©ì ì •ì˜ ë¶„ì„
    custom = integrator.custom_analysis("SELECT * FROM custom_view")
```

## ğŸ“– ìƒì„¸ ì˜ˆì œ

### ì˜ˆì œ 1: ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…

```python
from postgreSQLmodule.database import PostgreSQLManager

db = PostgreSQLManager()
db.connect()

# í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
tables = db.get_tables()
print(f"í…Œì´ë¸” ìˆ˜: {len(tables)}")

# í…Œì´ë¸” ì •ë³´ ì¡°íšŒ
for table in tables[:3]:
    info = db.get_table_info(table)
    size = db.get_table_size(table)
    rows = db.get_row_count(table)
    
    print(f"\n{table}:")
    print(f"  ì»¬ëŸ¼ ìˆ˜: {len(info)}")
    print(f"  í–‰ ìˆ˜: {rows:,}")
    print(f"  í¬ê¸°: {size.get('total_size', 'Unknown')}")

db.disconnect()
```

### ì˜ˆì œ 2: ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
from postgreSQLmodule.data_processor import DataProcessor
import pandas as pd

# ìƒ˜í”Œ ë°ì´í„°
df = pd.DataFrame({
    'User ID': range(1, 101),
    'User Name': [f'User {i}' for i in range(1, 101)],
    'Age': np.random.randint(18, 80, 100),
    'Income': np.random.normal(50000, 15000, 100)
})

processor = DataProcessor()

# 1. ì»¬ëŸ¼ëª… í‘œì¤€í™”
df = processor.standardize_columns(df)

# 2. ë°ì´í„° ì •ë¦¬
df = processor.clean_data(df, drop_duplicates=True)

# 3. í•„í„°ë§
filters = {'age': {'min': 25, 'max': 65}}
df = processor.filter_data(df, filters)

# 4. ì§‘ê³„
aggregated = processor.aggregate_data(
    df, 
    'age_group', 
    {'income': ['mean', 'median', 'std']}
)
```

### ì˜ˆì œ 3: ì¢…í•© ë¶„ì„

```python
from postgreSQLmodule.analyzer import DataAnalyzer

analyzer = DataAnalyzer()

# ê¸°ìˆ í†µê³„
desc_stats = analyzer.descriptive_statistics(df)

# ìƒê´€ê´€ê³„
correlation = analyzer.correlation_analysis(df, threshold=0.3)

# ì´ìƒì¹˜ íƒì§€
outliers = analyzer.outlier_analysis(df, methods=['iqr', 'zscore'])

# ì¸ì‚¬ì´íŠ¸ ìƒì„±
insights = analyzer.generate_insights(df)

print("ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
for insight in insights:
    print(f"- {insight}")
```

### ì˜ˆì œ 4: ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°

```python
from postgreSQLmodule.exporter import DataExporter

exporter = DataExporter("my_exports")

# ì—¬ëŸ¬ í˜•ì‹ìœ¼ë¡œ ë™ì‹œ ë‚´ë³´ë‚´ê¸°
files = exporter.export_multiple_formats(
    df, 
    "analysis_results", 
    ['csv', 'excel', 'json', 'html']
)

# ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸
analysis_results = {
    'descriptive': desc_stats,
    'correlation': correlation,
    'outliers': outliers
}

report_file = exporter.create_analysis_report(analysis_results)
print(f"ë¶„ì„ ë¦¬í¬íŠ¸: {report_file}")
```

## ğŸ—ï¸ ëª¨ë“ˆ êµ¬ì¡°

```
postgreSQLmodule/
â”œâ”€â”€ __init__.py          # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ database.py          # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë° ê´€ë¦¬
â”œâ”€â”€ data_processor.py    # ë°ì´í„° ì²˜ë¦¬ ë° ì „ì²˜ë¦¬
â”œâ”€â”€ analyzer.py          # ë°ì´í„° ë¶„ì„ ë° í†µê³„
â”œâ”€â”€ exporter.py          # ë°ì´í„° ë‚´ë³´ë‚´ê¸°
â”œâ”€â”€ integration.py       # í†µí•© ì›Œí¬í”Œë¡œìš°
â”œâ”€â”€ examples.py          # ì‚¬ìš© ì˜ˆì œ
â”œâ”€â”€ requirements.txt     # í•„ìˆ˜ íŒ¨í‚¤ì§€
â””â”€â”€ README.md           # ì´ íŒŒì¼
```

## ğŸ”§ ì„¤ì •

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì„ íƒì‚¬í•­)

```bash
export POSTGRES_PASSWORD="your_password"
export POSTGRES_HOST="your_host"
export POSTGRES_DB="your_database"
```

### ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •

```python
# ê¸°ë³¸ ì„¤ì •
db_config = {
    'host': '123.212.210.230',
    'port': 5432,
    'user': 'postgres',
    'database': 'gis_db',
    'password': None  # í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì…ë ¥ìœ¼ë¡œ ë°›ìŒ
}

# í†µí•© í´ë˜ìŠ¤ì— ì„¤ì • ì „ë‹¬
integrator = PostgreSQLIntegrator(db_config)
```

## ğŸ“Š ì§€ì›í•˜ëŠ” ë¶„ì„ ìœ í˜•

### ê¸°ìˆ í†µê³„
- í‰ê· , ì¤‘ì•™ê°’, ìµœë¹ˆê°’
- í‘œì¤€í¸ì°¨, ë¶„ì‚°
- ì‚¬ë¶„ìœ„ìˆ˜, ë²”ìœ„
- ì™œë„, ì²¨ë„

### ê³ ê¸‰ ë¶„ì„
- í”¼ì–´ìŠ¨/ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê´€ê³„
- ì •ê·œì„± ê²€ì • (Shapiro-Wilk)
- ì´ìƒì¹˜ íƒì§€ (IQR, Z-score)
- ì‹œê³„ì—´ ë¶„ì„ (ì¶”ì„¸, ê³„ì ˆì„±)
- ê°€ì„¤ ê²€ì • (t-test, ANOVA, Kruskal-Wallis)

### ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
- ê²°ì¸¡ê°’ ë¶„ì„
- ì¤‘ë³µ ë°ì´í„° íƒì§€
- ë°ì´í„° íƒ€ì… ê²€ì¦
- ì¹´ë””ë„ë¦¬í‹° ë¶„ì„

## ğŸ“ ë‚´ë³´ë‚´ê¸° í˜•ì‹

- **CSV**: ë²”ìš© ë°ì´í„° êµí™˜
- **Excel**: ë¹„ì¦ˆë‹ˆìŠ¤ ë¦¬í¬íŒ… (ë‹¤ì¤‘ ì‹œíŠ¸ ì§€ì›)
- **JSON**: API ì—°ë™ ë° ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
- **Parquet**: ë¹…ë°ì´í„° ì²˜ë¦¬ (ì••ì¶•ë¥  ìš°ìˆ˜)
- **HTML**: ì›¹ ê¸°ë°˜ ë¦¬í¬íŠ¸ (ì‹œê°ì  í…Œì´ë¸”)

## ğŸ” ë¡œê¹…

ëª¨ë“  ëª¨ë“ˆì€ Python loggingì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

```python
import logging

# ë¡œê¹… ë ˆë²¨ ì„¤ì •
logging.basicConfig(level=logging.INFO)

# íŠ¹ì • ëª¨ë“ˆë§Œ ë¡œê¹…
logger = logging.getLogger('postgreSQLmodule')
logger.setLevel(logging.DEBUG)
```

## ğŸš¨ ì—ëŸ¬ ì²˜ë¦¬

ëª¨ë“  í•¨ìˆ˜ëŠ” ì•ˆì „í•œ ì—ëŸ¬ ì²˜ë¦¬ë¥¼ í¬í•¨í•©ë‹ˆë‹¤:

- ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ ì‹œ ìë™ ì¬ì‹œë„ ì—†ìŒ (ëª…ì‹œì  ì²˜ë¦¬)
- ì˜ëª»ëœ ì¿¼ë¦¬ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜
- íŒŒì¼ ì €ì¥ ì‹¤íŒ¨ ì‹œ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
- ëª¨ë“  ì˜ˆì™¸ëŠ” ë¡œê·¸ì— ê¸°ë¡

## ğŸ”— ì˜ì¡´ì„±

### í•µì‹¬ íŒ¨í‚¤ì§€
- `psycopg2-binary`: PostgreSQL ì—°ê²°
- `pandas`: ë°ì´í„° ì²˜ë¦¬
- `numpy`: ìˆ˜ì¹˜ ê³„ì‚°

### ë¶„ì„ íŒ¨í‚¤ì§€
- `scipy`: í†µê³„ ë¶„ì„
- `matplotlib`, `seaborn`: ì‹œê°í™” ì§€ì›

### ë‚´ë³´ë‚´ê¸° íŒ¨í‚¤ì§€
- `openpyxl`: Excel ì§€ì›
- `pyarrow`: Parquet ì§€ì›

## ğŸ¤ ê¸°ì—¬

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„¼ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ê±°ë‚˜ ê¸°ëŠ¥ ìš”ì²­ì´ ìˆìœ¼ì‹œë©´ ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

---

**ì£¼ì˜ì‚¬í•­**: 
- ì´ ëª¨ë“ˆì€ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì— ì£¼ì˜í•˜ì„¸ìš”.
- ë¶„ì„ ê²°ê³¼ëŠ” `exports/` í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.
