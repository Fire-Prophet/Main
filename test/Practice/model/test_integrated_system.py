#!/usr/bin/env python3
"""
í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ ìŠ¤í¬ë¦½íŠ¸
- ì „ì²´ ì‹œìŠ¤í…œì˜ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸
- ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ ì œê³µ
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
"""

import os
import sys
import time
import numpy as np
import json
from datetime import datetime
import argparse

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from integrated_validation_system import IntegratedValidationSystem
    from model_validation import ModelValidator, create_synthetic_actual_data
    from realistic_fire_model import RealisticFireModel, DetailedWeatherConditions, HumanActivity
    from advanced_ca_model import AdvancedCAFireModel
    from ca_analyzer import CAAnalyzer
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("í•„ìš”í•œ ëª¨ë“  íŒŒì¼ì´ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)

class SystemTester:
    """ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.test_results = {}
        self.start_time = None
        
    def run_all_tests(self, output_dir="test_results"):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        self.start_time = time.time()
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. ê¸°ë³¸ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
        print("\n1ï¸âƒ£ ê¸°ë³¸ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
        self.test_basic_modules()
        
        # 2. ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        print("\n2ï¸âƒ£ ëª¨ë¸ ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        self.test_validation_system()
        
        # 3. í˜„ì‹¤ì„± ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
        print("\n3ï¸âƒ£ í˜„ì‹¤ì„± í–¥ìƒ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
        self.test_realistic_model()
        
        # 4. í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        print("\n4ï¸âƒ£ í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
        self.test_integrated_system(output_dir)
        
        # 5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        print("\n5ï¸âƒ£ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        self.run_performance_benchmark()
        
        # ê²°ê³¼ ìš”ì•½
        self.print_test_summary()
        
        return self.test_results
    
    def test_basic_modules(self):
        """ê¸°ë³¸ ëª¨ë“ˆë“¤ í…ŒìŠ¤íŠ¸"""
        tests = [
            ("CA ëª¨ë¸ ì´ˆê¸°í™”", self._test_ca_model),
            ("ì—°ë£Œ ë§µ ìƒì„±", self._test_fuel_map),
            ("ê¸°ë³¸ ì‹œë®¬ë ˆì´ì…˜", self._test_basic_simulation)
        ]
        
        for test_name, test_func in tests:
            try:
                print(f"  - {test_name}...", end=" ")
                result = test_func()
                self.test_results[test_name] = {"status": "âœ… ì„±ê³µ", "result": result}
                print("âœ…")
            except Exception as e:
                self.test_results[test_name] = {"status": "âŒ ì‹¤íŒ¨", "error": str(e)}
                print(f"âŒ ({e})")
    
    def test_validation_system(self):
        """ê²€ì¦ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        tests = [
            ("ê²€ì¦ê¸° ì´ˆê¸°í™”", self._test_validator_init),
            ("íŒ¨í„´ ê²€ì¦", self._test_pattern_validation),
            ("ì‹œê°„ì  ê²€ì¦", self._test_temporal_validation),
            ("í˜¼ë™ í–‰ë ¬ ê³„ì‚°", self._test_confusion_matrix)
        ]
        
        for test_name, test_func in tests:
            try:
                print(f"  - {test_name}...", end=" ")
                result = test_func()
                self.test_results[test_name] = {"status": "âœ… ì„±ê³µ", "result": result}
                print("âœ…")
            except Exception as e:
                self.test_results[test_name] = {"status": "âŒ ì‹¤íŒ¨", "error": str(e)}
                print(f"âŒ ({e})")
    
    def test_realistic_model(self):
        """í˜„ì‹¤ì„± ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""
        tests = [
            ("í˜„ì‹¤ì  ëª¨ë¸ ì´ˆê¸°í™”", self._test_realistic_init),
            ("ê¸°ìƒ ì¡°ê±´ ì„¤ì •", self._test_weather_setup),
            ("ë¹„í™” ì‹œë®¬ë ˆì´ì…˜", self._test_spotting),
            ("í™”ì¬ í–‰ë™ ê³„ì‚°", self._test_fire_behavior)
        ]
        
        for test_name, test_func in tests:
            try:
                print(f"  - {test_name}...", end=" ")
                result = test_func()
                self.test_results[test_name] = {"status": "âœ… ì„±ê³µ", "result": result}
                print("âœ…")
            except Exception as e:
                self.test_results[test_name] = {"status": "âŒ ì‹¤íŒ¨", "error": str(e)}
                print(f"âŒ ({e})")
    
    def test_integrated_system(self, output_dir):
        """í†µí•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        tests = [
            ("í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”", lambda: self._test_integrated_init(output_dir)),
            ("ëª¨ë¸ ì„¤ì •", self._test_model_setup),
            ("ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰", self._test_simulation_run),
            ("ë³´ê³ ì„œ ìƒì„±", lambda: self._test_report_generation(output_dir))
        ]
        
        for test_name, test_func in tests:
            try:
                print(f"  - {test_name}...", end=" ")
                result = test_func()
                self.test_results[test_name] = {"status": "âœ… ì„±ê³µ", "result": result}
                print("âœ…")
            except Exception as e:
                self.test_results[test_name] = {"status": "âŒ ì‹¤íŒ¨", "error": str(e)}
                print(f"âŒ ({e})")
    
    def run_performance_benchmark(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("  ì„±ëŠ¥ ì¸¡ì • ì¤‘...")
        
        grid_sizes = [(50, 50), (100, 100), (150, 150)]
        benchmark_results = {}
        
        for size in grid_sizes:
            try:
                start_time = time.time()
                
                # í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
                ca_model = AdvancedCAFireModel(size)
                fuel_map = np.random.choice(['TL1', 'TL2', 'GS1'], size=size)
                ca_model.fuel_map = fuel_map
                
                # ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜
                grid = np.zeros(size, dtype=int)
                center = (size[0]//2, size[1]//2)
                grid[center[0], center[1]] = 1
                
                for _ in range(10):  # 10ë‹¨ê³„ë§Œ ì‹¤í–‰
                    grid = ca_model._apply_fire_rules(grid)
                
                elapsed_time = time.time() - start_time
                benchmark_results[f"{size[0]}x{size[1]}"] = {
                    "time": elapsed_time,
                    "cells_per_second": (size[0] * size[1] * 10) / elapsed_time
                }
                
                print(f"    {size[0]}x{size[1]}: {elapsed_time:.3f}ì´ˆ")
                
            except Exception as e:
                benchmark_results[f"{size[0]}x{size[1]}"] = {"error": str(e)}
        
        self.test_results["ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"] = {"status": "âœ… ì™„ë£Œ", "result": benchmark_results}
    
    def _test_ca_model(self):
        """CA ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        model = AdvancedCAFireModel((50, 50))
        assert model.height == 50
        assert model.width == 50
        return {"grid_size": model.grid.shape}
    
    def _test_fuel_map(self):
        """ì—°ë£Œ ë§µ í…ŒìŠ¤íŠ¸"""
        fuel_map = np.random.choice(['TL1', 'TL2', 'GS1'], size=(30, 30))
        unique_fuels = np.unique(fuel_map)
        return {"unique_fuels": len(unique_fuels), "map_size": fuel_map.shape}
    
    def _test_basic_simulation(self):
        """ê¸°ë³¸ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸"""
        model = AdvancedCAFireModel((30, 30))
        model.fuel_map = np.random.choice(['TL1', 'GS1'], size=(30, 30))
        
        grid = np.zeros((30, 30), dtype=int)
        grid[15, 15] = 1  # ì¤‘ì•™ì— í™”ì¬
        
        new_grid = model._apply_fire_rules(grid)
        burned_cells = np.sum(new_grid > 0)
        
        return {"initial_fire": 1, "after_step": int(burned_cells)}
    
    def _test_validator_init(self):
        """ê²€ì¦ê¸° ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        test_results = {
            'final_grid': np.random.randint(0, 3, size=(20, 20)),
            'step_history': [np.random.randint(0, 3, size=(20, 20)) for _ in range(5)],
            'fuel_map': np.random.choice(['TL1', 'GS1'], size=(20, 20))
        }
        
        validator = ModelValidator(test_results)
        return {"validator_created": True}
    
    def _test_pattern_validation(self):
        """íŒ¨í„´ ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        test_grid = np.zeros((20, 20), dtype=int)
        test_grid[8:12, 8:12] = 2  # ì‘ì€ ì—°ì†Œ ì˜ì—­
        
        test_results = {
            'final_grid': test_grid,
            'fuel_map': np.random.choice(['TL1'], size=(20, 20))
        }
        
        validator = ModelValidator(test_results)
        metrics = validator.validate_spread_pattern()
        
        return {
            "compactness": metrics.get('compactness', 0),
            "total_burned": metrics.get('total_burned_area', 0)
        }
    
    def _test_temporal_validation(self):
        """ì‹œê°„ì  ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        step_history = []
        for i in range(5):
            grid = np.zeros((20, 20), dtype=int)
            # ì ì§„ì ìœ¼ë¡œ í™•ì‚°
            grid[9:11+i, 9:11+i] = 2
            step_history.append(grid)
        
        test_results = {
            'step_history': step_history,
            'fuel_map': np.random.choice(['TL1'], size=(20, 20))
        }
        
        validator = ModelValidator(test_results)
        metrics = validator.validate_temporal_progression()
        
        return {
            "growth_consistency": metrics.get('growth_consistency', 0),
            "mean_rate": metrics['burn_rate_progression'].get('mean_rate', 0)
        }
    
    def _test_confusion_matrix(self):
        """í˜¼ë™ í–‰ë ¬ í…ŒìŠ¤íŠ¸"""
        predicted = np.random.randint(0, 2, size=(20, 20))
        actual = np.random.randint(0, 2, size=(20, 20))
        
        test_results = {'final_grid': predicted}
        validator = ModelValidator(test_results)
        
        metrics = validator.calculate_confusion_matrix(actual)
        
        return {
            "accuracy": metrics.get('accuracy', 0),
            "f1_score": metrics.get('f1_score', 0)
        }
    
    def _test_realistic_init(self):
        """í˜„ì‹¤ì  ëª¨ë¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        model = RealisticFireModel((30, 30), cell_size=30.0)
        return {"grid_size": (model.height, model.width), "cell_size": model.cell_size}
    
    def _test_weather_setup(self):
        """ê¸°ìƒ ì¡°ê±´ ì„¤ì • í…ŒìŠ¤íŠ¸"""
        weather = DetailedWeatherConditions(
            temperature=30.0,
            relative_humidity=40.0,
            wind_speed=10.0,
            wind_direction=180.0,
            atmospheric_pressure=1013.0,
            solar_radiation=600.0,
            precipitation=0.0,
            drought_index=0.6,
            fire_weather_index=70.0,
            stability_class='C'
        )
        
        return {
            "temperature": weather.temperature,
            "wind_speed": weather.wind_speed,
            "fire_weather_index": weather.fire_weather_index
        }
    
    def _test_spotting(self):
        """ë¹„í™” í…ŒìŠ¤íŠ¸"""
        model = RealisticFireModel((30, 30))
        model.weather_conditions = DetailedWeatherConditions(
            temperature=35.0, relative_humidity=20.0, wind_speed=20.0,
            wind_direction=270.0, atmospheric_pressure=1013.0,
            solar_radiation=800.0, precipitation=0.0,
            drought_index=0.8, fire_weather_index=90.0, stability_class='B'
        )
        
        # ê°•í•œ í™”ì¬ ì¡°ê±´
        model.ember_source_map = np.zeros((30, 30))
        model.ember_source_map[15, 15] = 1.0  # ê°•í•œ ë¶ˆì”¨ ìƒì„±
        
        grid = np.zeros((30, 30), dtype=int)
        grid[15, 15] = 1
        
        new_ignitions = model.simulate_spotting(grid, max_spot_distance=500)
        
        return {
            "spotting_events": len(new_ignitions),
            "wind_speed": model.weather_conditions.wind_speed
        }
    
    def _test_fire_behavior(self):
        """í™”ì¬ í–‰ë™ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        model = RealisticFireModel((20, 20))
        model.fuel_map = np.random.choice(['TL1', 'TL2'], size=(20, 20))
        
        grid = np.zeros((20, 20), dtype=int)
        grid[10, 10] = 1
        
        behavior_data = model.calculate_fire_behavior(grid)
        
        return {
            "max_intensity": float(np.max(behavior_data['fire_intensity'])),
            "max_flame_length": float(np.max(behavior_data['flame_length']))
        }
    
    def _test_integrated_init(self, output_dir):
        """í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        self.integrated_system = IntegratedValidationSystem()
        self.integrated_system.config['output']['output_directory'] = output_dir
        return {"config_loaded": True}
    
    def _test_model_setup(self):
        """ëª¨ë¸ ì„¤ì • í…ŒìŠ¤íŠ¸"""
        fuel_map = np.random.choice(['TL1', 'TL2', 'GS1'], size=(40, 40))
        elevation_map = np.random.randint(100, 500, size=(40, 40))
        
        weather_data = {
            'temperature': 30.0,
            'relative_humidity': 35.0,
            'wind_speed': 15.0,
            'wind_direction': 180.0,
            'atmospheric_pressure': 1013.0,
            'solar_radiation': 700.0,
            'precipitation': 0.0,
            'drought_index': 0.7,
            'fire_weather_index': 80.0,
            'stability_class': 'C'
        }
        
        self.integrated_system.setup_models(fuel_map, elevation_map, weather_data)
        return {"models_setup": True}
    
    def _test_simulation_run(self):
        """ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ í…ŒìŠ¤íŠ¸"""
        ignition_points = [(20, 20)]
        
        # ì§§ì€ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
        self.integrated_system.config['simulation']['max_steps'] = 10
        
        results = self.integrated_system.run_integrated_simulation(ignition_points)
        
        return {
            "total_steps": results.get('total_steps', 0),
            "final_burned": int(np.sum(results['final_grid'] == 2))
        }
    
    def _test_report_generation(self, output_dir):
        """ë³´ê³ ì„œ ìƒì„± í…ŒìŠ¤íŠ¸"""
        # ê°„ë‹¨í•œ ê²€ì¦ ì‹¤í–‰
        validation_results = self.integrated_system.run_comprehensive_validation()
        
        # ë³´ê³ ì„œ ìƒì„±
        report_path = self.integrated_system.generate_comprehensive_report(output_dir)
        
        return {
            "report_generated": os.path.exists(report_path),
            "report_path": report_path
        }
    
    def print_test_summary(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results.values() 
                          if result['status'].startswith('âœ…'))
        failed_tests = total_tests - passed_tests
        
        print(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}")
        print(f"ì„±ê³µ: {passed_tests} âœ…")
        print(f"ì‹¤íŒ¨: {failed_tests} âŒ")
        print(f"ì„±ê³µë¥ : {(passed_tests/total_tests)*100:.1f}%")
        
        if self.start_time:
            total_time = time.time() - self.start_time
            print(f"ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
        
        # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ìƒì„¸ ì •ë³´
        if failed_tests > 0:
            print("\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸:")
            for test_name, result in self.test_results.items():
                if result['status'].startswith('âŒ'):
                    print(f"  - {test_name}: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        
        print("\n" + "=" * 60)

def create_demo_scenario():
    """ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
    print("ğŸ¬ ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤: ì‚°ë¶ˆ í™•ì‚° ì‹œë®¬ë ˆì´ì…˜")
    print("=" * 60)
    
    # ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •
    print("\nğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •:")
    print("- ìœ„ì¹˜: ê°€ìƒì˜ ì‚°ë¦¼ ì§€ì—­ (100x100 ê²©ì)")
    print("- ì—°ë£Œ: í˜¼í•©ë¦¼ (ì¹¨ì—½ìˆ˜ë¦¼, í™œì—½ìˆ˜ë¦¼, ê´€ëª©)")
    print("- ê¸°ìƒ: ê±´ì¡°í•˜ê³  ë°”ëŒì´ ê°•í•œ ì¡°ê±´")
    print("- ì°©í™”: ìº í•‘ì¥ ê·¼ì²˜ì—ì„œ ë°œìƒ")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = IntegratedValidationSystem()
    
    # í˜„ì‹¤ì ì¸ ë°ì´í„° ìƒì„±
    grid_size = (100, 100)
    
    # ì—°ë£Œ ë§µ (í˜„ì‹¤ì ì¸ ë¶„í¬)
    fuel_map = np.full(grid_size, 'TL1', dtype='<U3')
    
    # ì¹¨ì—½ìˆ˜ë¦¼ ì§€ì—­ (í™”ì¬ ìœ„í—˜ ë†’ìŒ)
    fuel_map[20:60, 20:60] = 'TL2'
    fuel_map[30:50, 30:50] = 'TL3'
    
    # ê´€ëª© ì§€ì—­
    fuel_map[60:80, 40:80] = 'TU2'
    
    # ì´ˆì§€ ì§€ì—­
    fuel_map[10:30, 70:90] = 'GS2'
    fuel_map[70:90, 10:30] = 'GR1'
    
    # ì§€í˜• (ê³ ë„ ë³€í™”)
    x, y = np.meshgrid(np.linspace(0, 10, 100), np.linspace(0, 10, 100))
    elevation_map = (200 + 300 * np.sin(x) * np.cos(y) + 
                    100 * np.random.random(grid_size)).astype(int)
    
    # ìœ„í—˜í•œ ê¸°ìƒ ì¡°ê±´
    weather_data = {
        'temperature': 38.0,        # ë†’ì€ ì˜¨ë„
        'relative_humidity': 18.0,  # ë‚®ì€ ìŠµë„
        'wind_speed': 25.0,         # ê°•í•œ ë°”ëŒ
        'wind_direction': 225.0,    # ë‚¨ì„œí’
        'atmospheric_pressure': 1008.0,
        'solar_radiation': 900.0,
        'precipitation': 0.0,       # ë¬´ê°•ìˆ˜
        'drought_index': 0.9,       # ê·¹ì‹¬í•œ ê°€ë­„
        'fire_weather_index': 95.0, # ê·¹ë„ë¡œ ìœ„í—˜
        'stability_class': 'A'      # ë¶ˆì•ˆì •í•œ ëŒ€ê¸°
    }
    
    # ì¸ê°„ í™œë™ (ìº í•‘ì¥, ë„ë¡œ)
    human_data = {
        'population_density': 0.2,
        'road_density': 0.4,
        'recreation_areas': [(15, 15), (25, 20)],  # ìº í•‘ì¥
        'industrial_sites': [],
        'power_lines': [(10, 10, 90, 90)],  # ì†¡ì „ì„ 
        'ignition_risk_map': np.random.random(grid_size) * 0.5
    }
    
    print("\nğŸ”§ ëª¨ë¸ ì„¤ì • ì¤‘...")
    system.setup_models(fuel_map, elevation_map, weather_data, human_data)
    
    print("\nğŸ”¥ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘...")
    # ìº í•‘ì¥ ê·¼ì²˜ì—ì„œ ì°©í™”
    ignition_points = [(18, 18), (22, 22)]
    
    # ë” ê¸´ ì‹œë®¬ë ˆì´ì…˜
    system.config['simulation']['max_steps'] = 50
    system.config['simulation']['validation_interval'] = 10
    
    results = system.run_integrated_simulation(ignition_points)
    
    print("\nğŸ“Š ê²€ì¦ ë¶„ì„ ì¤‘...")
    validation_results = system.run_comprehensive_validation()
    
    print("\nğŸ“„ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    report_path = system.generate_comprehensive_report("demo_scenario_results")
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“ˆ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")
    print("=" * 60)
    
    final_grid = results['final_grid']
    total_burned = np.sum(final_grid == 2)
    total_cells = final_grid.size
    
    print(f"ì´ ì—°ì†Œ ë©´ì : {total_burned:,} ì…€ ({total_burned * 30 * 30 / 10000:.1f} ha)")
    print(f"ì—°ì†Œ ë¹„ìœ¨: {(total_burned/total_cells)*100:.2f}%")
    print(f"ì‹œë®¬ë ˆì´ì…˜ ë‹¨ê³„: {results['total_steps']}")
    
    # í˜„ì‹¤ì„± ì§€í‘œ
    if hasattr(system.realistic_model, 'spotting_events'):
        print(f"ë¹„í™” ì´ë²¤íŠ¸: {len(system.realistic_model.spotting_events)}íšŒ")
    
    if 'confusion_matrix' in validation_results:
        cm = validation_results['confusion_matrix']
        print(f"ëª¨ë¸ ì •í™•ë„: {cm.get('accuracy', 0):.3f}")
    
    print(f"\nğŸ“ ìƒì„¸ ê²°ê³¼: {report_path}")
    print("\nğŸ‰ ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ ì™„ë£Œ!")
    
    return system, results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='í†µí•© í™”ì¬ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸')
    parser.add_argument('--mode', choices=['test', 'demo', 'both'], default='both',
                       help='ì‹¤í–‰ ëª¨ë“œ ì„ íƒ')
    parser.add_argument('--output', default='test_results',
                       help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    print("ğŸ”¥ í•œêµ­ ì‚°ë¦¼ í™”ì¬ í™•ì‚° ì‹œë®¬ë ˆì´ì…˜ ì‹œìŠ¤í…œ")
    print("=" * 60)
    print(f"ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ì‹¤í–‰ ëª¨ë“œ: {args.mode}")
    print(f"ê²°ê³¼ ì €ì¥: {args.output}")
    
    if args.mode in ['test', 'both']:
        print("\nğŸ§ª ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        tester = SystemTester()
        test_results = tester.run_all_tests(args.output)
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        with open(os.path.join(args.output, 'test_results.json'), 'w', encoding='utf-8') as f:
            json.dump(test_results, f, indent=2, ensure_ascii=False, default=str)
    
    if args.mode in ['demo', 'both']:
        print("\nğŸ¬ ë°ëª¨ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰")
        demo_system, demo_results = create_demo_scenario()
    
    print(f"\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ! ê²°ê³¼ëŠ” '{args.output}' ë””ë ‰í† ë¦¬ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()
